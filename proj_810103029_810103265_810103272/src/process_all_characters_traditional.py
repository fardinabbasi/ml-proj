# -*- coding: utf-8 -*-
"""process_all_characters.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ha2WZzjYme67LtFcx5k9_vMVd50jHvhq
"""

from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.metrics import (
    silhouette_score, davies_bouldin_score,
    adjusted_rand_score, normalized_mutual_info_score,
    homogeneity_score, completeness_score, v_measure_score
)
from sklearn.preprocessing import StandardScaler
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import importlib


from display_closest_and_farthest_patches_with_center_attribute_traditional import display_closest_and_farthest_patches_with_center_attribute
from display_closest_and_farthest_patches_without_center_attribute_traditional import display_closest_and_farthest_patches_without_center_attribute
from display_cluster_patches_traditional import display_cluster_patches
from visualize_clusters_traditional import visualize_clusters
from extract_features_traditional import extract_features

# importlib.reload(display_cluster_patches)



def process_all_characters(
    images, boxes,
    val_images=None, val_boxes=None, val_expressions=None,
    show_internal_winner_visuals=True
):
    MIN_CLUSTERS = 5  # enforce ≥5 clusters everywhere (excluding -1)

    # --- helpers ---
    def _external_metrics(y_true, y_pred):
        return {
            "ARI": adjusted_rand_score(y_true, y_pred),
            "NMI": normalized_mutual_info_score(y_true, y_pred),
            "Homogeneity": homogeneity_score(y_true, y_pred),
            "Completeness": completeness_score(y_true, y_pred),
            "V-Measure": v_measure_score(y_true, y_pred),
        }

    def _val_patch_labels_from_boxes(val_boxes, val_expressions):
        labels, keep = [], []
        for boxes_i, expr in zip(val_boxes, val_expressions or []):
            if not isinstance(expr, str):
                keep.extend([False]*len(boxes_i)); continue
            order = np.argsort([b[0] for b in boxes_i])
            boxes_sorted = [boxes_i[t] for t in order]
            if len(boxes_sorted) != len(expr):
                keep.extend([False]*len(boxes_i)); continue
            labels.extend(list(expr))
            keep.extend([True]*len(boxes_i))
        return np.array(labels), np.array(keep, dtype=bool)

    def _new_model_from_method_name(name):
        if name.startswith("KMeans_k="):
            k = int(name.split("=")[1]);  return KMeans(n_clusters=k, random_state=42)
        if name.startswith("Agglomerative_k="):
            k = int(name.split("=")[1]);  return AgglomerativeClustering(n_clusters=k, linkage='ward')
        if name.startswith("DBSCAN_eps="):
            eps = float(name.replace("DBSCAN_eps=","").split("_min=")[0])
            min_s = int(name.split("_min=")[1])
            return DBSCAN(eps=eps, min_samples=min_s)
        raise ValueError(f"Unrecognized method name: {name}")

    def _n_clusters(labels):
        """count clusters excluding noise (-1)"""
        labs = np.unique(labels)
        return len(labs) - (1 if -1 in labs else 0)

    # --- 0) build features ---
    feature_bags = { 'raw_pixels': [], 'hog': [], 'sift': [], 'lbp': [], 'combined': [] }
    all_train_patches = []

    for image, img_boxes in zip(images, boxes):
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        for (x, y, w, h) in img_boxes:
            x, y, w, h = map(int, (round(x), round(y), round(w), round(h)))
            if w <= 0 or h <= 0:
                continue
            patch = gray[max(0,y):min(y+h, gray.shape[0]), max(0,x):min(x+w, gray.shape[1])]
            if patch.size == 0:
                continue
            feats = extract_features(patch)
            for k in feature_bags: feature_bags[k].append(feats[k])
            all_train_patches.append(patch)

    val_feature_bags = {k: [] for k in feature_bags}
    if (val_images is not None) and (val_boxes is not None):
        for image, img_boxes in zip(val_images, val_boxes):
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
            for (x, y, w, h) in img_boxes:
                x, y, w, h = map(int, (round(x), round(y), round(w), round(h)))
                if w <= 0 or h <= 0:
                    continue
                patch = gray[max(0,y):min(y+h, gray.shape[0]), max(0,x):min(x+w, gray.shape[1])]
                if patch.size == 0:
                    continue
                feats = extract_features(patch)
                for k in val_feature_bags: val_feature_bags[k].append(feats[k])

    y_val_chars, keep_mask = (None, None)
    if (val_boxes is not None) and (val_expressions is not None):
        y_val_chars, keep_mask = _val_patch_labels_from_boxes(val_boxes, val_expressions)

    # --- 1) search space on TRAIN ---
    k_values = [8, 10, 12, 14, 16, 18]
    dbscan_params = [(0.1, 3), (0.2, 3), (0.3, 3)]

    internal_winners = []
    internal_visual_payloads = []

    # --- 2) choose INTERNAL winners (must pass ≥5 clusters on TRAIN & VAL) ---
    for ft_name, feats_list in feature_bags.items():
        X_tr_raw = np.array(feats_list)
        scaler = StandardScaler().fit(X_tr_raw)
        X_tr = scaler.transform(X_tr_raw)
        X_val = scaler.transform(np.array(val_feature_bags[ft_name])) if val_feature_bags[ft_name] else None

        best_by_algo = {}  # algo -> (row, payload, val_labels, n_cl_val)

        for k in k_values:
            algos = {
                f'KMeans_k={k}': KMeans(n_clusters=k, random_state=42),
                f'Agglomerative_k={k}': AgglomerativeClustering(n_clusters=k, linkage='ward'),
            }
            for eps, min_s in dbscan_params:
                algos[f'DBSCAN_eps={eps}_min={min_s}'] = DBSCAN(eps=eps, min_samples=min_s)

            for name, model in algos.items():
                try:
                    # TRAIN
                    pred_tr = model.fit_predict(X_tr)
                    pred_tr = np.asarray(pred_tr, dtype=int)          # enforce ints
                    n_cl_tr = _n_clusters(pred_tr)
                    if n_cl_tr < MIN_CLUSTERS:
                        continue  # drop immediately

                    sil_tr = silhouette_score(X_tr, pred_tr)
                    db_tr  = davies_bouldin_score(X_tr, pred_tr)

                    # VAL internal (must also pass threshold to keep the winner at all)
                    sil_val = db_val = None
                    val_labels = None
                    n_cl_val = None
                    if X_val is not None:
                        try:
                            if hasattr(model, "predict"):
                                pv = model.predict(X_val)          # KMeans
                            else:
                                pv = _new_model_from_method_name(name).fit_predict(X_val)  # refit
                            pv = np.asarray(pv, dtype=int)         # <-- enforce ints

                            n_cl_val = _n_clusters(pv)
                            if n_cl_val >= MIN_CLUSTERS and len(np.unique(pv)) > 1:
                                sil_val = silhouette_score(X_val, pv)
                                db_val  = davies_bouldin_score(X_val, pv)
                                val_labels = pv
                            else:
                                continue
                        except Exception:
                            continue

                    algo = name.split("_")[0]
                    row = {
                        "Feature Type": ft_name,
                        "Method": name,
                        "Method Type": algo,
                        "Silhouette (Train)": sil_tr,
                        "Davies-Bouldin (Train)": db_tr,
                        "Silhouette (Val)": sil_val,
                        "Davies-Bouldin (Val)": db_val,
                        "Clusters Found (Train)": n_cl_tr,
                        "Clusters Found (Val)": n_cl_val,
                    }
                    payload = {"model": model, "X_tr": X_tr, "pred_tr": pred_tr,
                               "method_name": name, "ft_name": ft_name}

                    # choose best by Silhouette(Train), tie-break by lower DB(Train)
                    take = False
                    if algo not in best_by_algo:
                        take = True
                    else:
                        prev = best_by_algo[algo][0]
                        if row["Silhouette (Train)"] > prev["Silhouette (Train)"]:
                            take = True
                        elif np.isclose(row["Silhouette (Train)"], prev["Silhouette (Train)"]) and \
                             row["Davies-Bouldin (Train)"] < prev["Davies-Bouldin (Train)"]:
                            take = True
                    if take:
                        best_by_algo[algo] = (row, payload, val_labels, n_cl_val)

                except Exception:
                    continue

        # keep winners (already passed Val threshold)
        for _, (row, payload, _, _) in best_by_algo.items():
            internal_winners.append(row)
            internal_visual_payloads.append((payload, all_train_patches))

    # --- 3) INTERNAL table (only ≥5 clusters on both splits) ---
    internal_winners_df = pd.DataFrame(internal_winners)
    if not internal_winners_df.empty:
        internal_winners_df = internal_winners_df.sort_values(
            ["Silhouette (Train)"],
            ascending=[False]
        )
        print("\n=== Internal winners (≥5 clusters on Train & Val) ===")
        display(internal_winners_df)

    # --- 4) EXTERNAL metrics for the SAME winners (refit on Val; keep only ≥5 clusters) ---
    external_rows = []
    if (val_boxes is not None) and (val_expressions is not None) and not internal_winners_df.empty:
        y_val_chars, keep_mask = _val_patch_labels_from_boxes(val_boxes, val_expressions)
        scalers = {ft: StandardScaler().fit(np.array(feats))
                   for ft, feats in feature_bags.items()}

        for _, row in internal_winners_df.iterrows():
            ft_name = row["Feature Type"]
            method  = row["Method"]
            if not val_feature_bags[ft_name]:
                continue
            X_val = scalers[ft_name].transform(np.array(val_feature_bags[ft_name]))

            try:
                model_val = _new_model_from_method_name(method)
                pred_val_full = model_val.fit_predict(X_val)      # refit on Val
                pred_val_full = np.asarray(pred_val_full, dtype=int)  # <-- enforce ints
                if _n_clusters(pred_val_full) < MIN_CLUSTERS:
                    continue
                pred_val = np.asarray(pred_val_full)[keep_mask]
                y_true   = np.asarray(list(y_val_chars))
                if len(pred_val) == len(y_true) and len(np.unique(pred_val)) > 1:
                    external_rows.append({
                        "Feature Type": ft_name,
                        "Method": method,
                        "Method Type": row["Method Type"],
                        **_external_metrics(y_true, pred_val)
                    })
            except Exception:
                continue

    external_for_winners_df = pd.DataFrame(external_rows)
    if not external_for_winners_df.empty:
        external_for_winners_df = external_for_winners_df.sort_values(
            ["ARI"], ascending=[False]
        )
        print("\n=== External metrics on VAL (winners, ≥5 clusters) ===")
        display(external_for_winners_df)

    # --- 5) Visuals: only winners that passed both thresholds ---
    if show_internal_winner_visuals and len(internal_visual_payloads):
        for payload, patches in internal_visual_payloads:
            model = payload["model"]; X_tr = payload["X_tr"]; pred_tr = payload["pred_tr"]
            meth  = payload["method_name"]; ft = payload["ft_name"]
            for dr in ("pca", "tsne"):
                visualize_clusters(X_tr, pred_tr, meth, ft, dr)
            display_cluster_patches(patches, pred_tr, meth, ft)
            if hasattr(model, "cluster_centers_"):
                display_closest_and_farthest_patches_with_center_attribute(
                    patches, X_tr, pred_tr, model, meth, ft
                )
            else:
                display_closest_and_farthest_patches_without_center_attribute(
                    patches, X_tr, pred_tr, model, meth, ft
                )

    return internal_winners_df, external_for_winners_df